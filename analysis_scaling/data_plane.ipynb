{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d19c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd \n",
    "import os\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe1824e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lensize_img(path):\n",
    "    img_list = []\n",
    "    img_res = {}\n",
    "    for img in os.listdir(path):\n",
    "        if img.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(path, img)\n",
    "            img_list.append(img)\n",
    "            if Image.open(img_path).size in img_res:\n",
    "                img_res[Image.open(img_path).size] += 1 \n",
    "            else: \n",
    "                img_res[Image.open(img_path).size] = 1\n",
    "\n",
    "    return len(img_list), img_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fb9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"nelyg8002000/commercial-aircraft-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ae728f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r\"C:\\Users\\illya\\.cache\\kagglehub\\datasets\\nelyg8002000\\commercial-aircraft-dataset\\versions\\1\\1_Liner TF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "137df799",
   "metadata": {},
   "outputs": [],
   "source": [
    "res, _ = lensize_img(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e661ba9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6538"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "309171a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4875.0, 975.0, 650.0, 6500.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = 0.75 * 6500\n",
    "valid = 0.15 * 6500\n",
    "test = 0.1 * 6500\n",
    "train, valid, test, train + valid + test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d807549",
   "metadata": {},
   "outputs": [],
   "source": [
    "lovely_dime = [128, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "448f586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = 'B:\\\\CV Drone Detection\\\\scaled\\\\valid\\\\notAdrone'\n",
    "train = 'B:\\\\CV Drone Detection\\\\scaled\\\\train\\\\notAdrone'\n",
    "test = 'B:\\\\CV Drone Detection\\\\scaled\\\\test\\\\notAdrone'\n",
    "out_dirs = [test, validation, train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34bf6737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(in_dir, out_dirs, lovely_dime):\n",
    "    for d in out_dirs:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    counter = 0 \n",
    "    processed = []\n",
    "\n",
    "    for img in os.listdir(in_dir):\n",
    "        if img.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            img_path = os.path.join(in_dir, img)\n",
    "            image = cv2.imread(img_path)\n",
    "\n",
    "            height, width = image.shape[:2]\n",
    "            scale_factor_W, scale_factor_H = lovely_dime\n",
    "            scale = min(scale_factor_W / width, scale_factor_H / height)\n",
    "\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "\n",
    "            scaled_image = cv2.resize(\n",
    "                                    src=image,\n",
    "                                    dsize=(new_width, new_height),\n",
    "                                    interpolation=cv2.INTER_CUBIC\n",
    "                                )\n",
    "\n",
    "            canvas = np.zeros((scale_factor_H, scale_factor_W, 3), dtype=np.uint8)\n",
    "            x_offset = (scale_factor_W - new_width) // 2\n",
    "            y_offset = (scale_factor_H - new_height) // 2\n",
    "            canvas[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = scaled_image\n",
    "\n",
    "            if counter < 650:\n",
    "                save_dir = out_dirs[0]\n",
    "            elif counter < 975:\n",
    "                save_dir = out_dirs[1]\n",
    "            else:\n",
    "                save_dir = out_dirs[2]\n",
    "\n",
    "            save_path = os.path.join(save_dir, img)\n",
    "            cv2.imwrite(save_path, canvas)\n",
    "            processed.append(save_path)\n",
    "            counter += 1\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4ee86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = scaler(DATA_DIR, out_dirs, lovely_dime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86acdd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, _ = lensize_img(validation)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59f76021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5563"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, _ = lensize_img(train)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e22d5066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, _ = lensize_img(test)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ef69f",
   "metadata": {},
   "source": [
    "6500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
